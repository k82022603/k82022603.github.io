---
title: "SKILL은 왜 잘 작동할까: 원리와 실천의 개발자 가이드"
date: 2026-01-11 09:00:00 +0900
categories: [AI,  Agent Skills]
mermaid: [True]
tags: [AI,  Material,  claude-code,  claude-skills,  Claude.write]
---

## 들어가며: 질문의 시작

2025년 말에 시작된 하나의 질문이 있습니다. "SKILL은 왜 잘 작동할까?" 이 질문은 단순해 보이지만, AI 시스템의 작동 원리, 프롬프팅의 본질, 그리고 인지 과정의 근본까지 닿아있는 깊은 탐구입니다. 2026년 초에도 이 질문은 계속 진화하고 있으며, "원리와 친해지는 프롬프팅", "원리를 생각하는 프롬프팅"이라는 화두로 이어지고 있습니다.

Claude 웹 인터페이스의 SKILL 시스템은 매우 매력적인 도구입니다. 특히 스킬 크리에이터를 활성화하면, 자연스러운 대화 속에서 그 부산물로 SKILL을 만들고 즉시 등록할 수 있는 깔끔한 워크플로우를 제공합니다. 등록된 SKILL은 상황에 맞게 자동으로 트리거되거나, 명시적으로 호출할 수 있습니다. 물론 너무 많은 SKILL을 활성화하면 오히려 방해가 될 수 있기 때문에 적정 수준의 관리가 필요합니다.

이 문서는 SKILL이 왜 효과적으로 작동하는지, 그 원리를 이해하고 실제로 활용하기 위한 개발자 가이드입니다. 표면적인 설명을 넘어서, AI 시스템의 근본적인 작동 방식과 프롬프팅의 철학적 기반까지 탐구합니다.

## SKILL의 본질: 정책의 텍스트 인코딩

SKILL을 단순히 "지침(instruction)"이나 "가이드라인"으로만 보는 것은 그 본질을 놓치는 것입니다. 더 정확한 이해는 SKILL을 "정책(policy)의 텍스트 인코딩"으로 보는 관점입니다. 여기서 정책이란 특정 상황(state)에서 어떤 행동(action)을 취할지 결정하는 함수를 의미합니다.

AI 모델의 관점에서 보면, SKILL은 모델이 이미 학습한 광범위한 행동 공간 중에서 현재 맥락에 적합한 특정 영역으로 주의(attention)를 라우팅하고, 출력 분포를 특정 방향으로 조정(nudge)하는 역할을 합니다. 이는 단순히 정보를 추가하는 것이 아니라, 모델의 내부 상태와 계산 경로를 조건화(conditioning)하는 것입니다.

이러한 관점에서 SKILL이 효과적인 이유는 크게 세 가지로 정리할 수 있습니다. 첫째, SKILL은 프리필(prefill)된 토큰으로 작동합니다. 사용자의 입력이 들어오기 전에 이미 컨텍스트에 포함되어 있어, 모델의 초기 상태를 특정 방향으로 설정합니다. 둘째, SKILL은 고밀도 정보(dense information)를 담고 있습니다. 짧은 텍스트 안에 특정 도메인의 핵심 패턴, 제약사항, 예시가 압축되어 있어, 모델이 효율적으로 참조할 수 있습니다. 셋째, SKILL은 조건부 활성화(conditional activation)가 가능합니다. 모든 SKILL이 항상 활성화되는 것이 아니라, 현재 대화의 맥락에 따라 선택적으로 트리거되므로 노이즈를 최소화합니다.

## Domain-Priming: 무작위성과 통찰의 만남

Domain-priming은 SKILL의 잠재력을 보여주는 흥미로운 사례입니다. 이 SKILL의 핵심 아이디어는 파레이돌리아(Pareidolia)나 아포페니아(Apophenia) 같은 인지 현상을 활용하는 것입니다. 파레이돌리아는 무작위적인 자극에서 의미 있는 패턴을 인식하는 경향이며, 아포페니아는 무관한 것들 사이에서 연결을 찾으려는 성향입니다.

Domain-priming은 무작위적인 알파벳 4글자 조합을 100개 정도 생성하고, 이를 두문자어(acronym)로 해석했을 때 현재 대화 맥락에서 인사이트를 줄 수 있는 개념을 탐색합니다. 이 과정에서 놀라운 일이 일어납니다. 완전히 무작위적으로 생성된 문자 조합이 현재 탐구하는 주제와 연결되어 새로운 관점을 제공하는 것입니다.

예를 들어 "AI가 자신의 작동 방식을 어떻게 이해하는가"라는 질문을 탐구할 때 domain-priming을 사용했다고 가정해봅시다. 100개의 무작위 코드 중에서 USIE(Understanding Self Is Ephemeral, 자기 이해는 일시적), WIRK(What I Really Know, 진짜 아는 것), ZPOT(Zone of Possible Output Trajectories, 가능한 출력 궤적의 영역), COHP(Conditioning Over Hidden Process, 숨겨진 과정에 대한 조건화) 같은 개념이 추출됩니다.

흥미로운 점은 이러한 개념들이 단순히 우연의 일치가 아니라는 것입니다. 인간의 뇌가 무작위 자극에서 패턴을 찾는 것처럼, AI 모델도 현재 활성화된 도메인 맥락을 필터로 사용하여 무작위 조합에서 의미를 추출합니다. 이 과정에서 직접 질문했다면 떠올리지 못했을 새로운 프레임워크가 발견될 수 있습니다.

Domain-priming의 실제 적용 과정을 살펴보면, 먼저 현재 탐구하는 문제나 막힌 지점을 명확히 합니다. 표면적 설명을 넘어서는 깊은 통찰이 필요한 순간입니다. 그 다음 파라미터를 설정합니다. 일반적으로 100개의 4글자 조합이 적절하며, 재현성을 위해 시드값을 설정할 수도 있습니다. 생성된 코드들을 현재 맥락에서 읽어보고, 유의미하게 해석되는 것들을 선별합니다. 선택된 개념들 사이의 연결 구조를 탐색하면서 더 큰 프레임워크를 발견합니다. 마지막으로 각 개념에 대해 가설-반가설-검증의 과정을 거치며 아포페니아의 함정을 피합니다.

위의 예시에서 선택된 개념들은 POMDP(부분관측 마르코프 의사결정) 컨트롤러라는 통합 프레임으로 연결되었습니다. SIPN은 스킬이 정책을 조건화한다는 의미이고, ZPOT는 정책이 출력 분포를 좁힌다는 개념입니다. COHP는 내부 과정이 관찰 불가능하다는 부분관측의 특성을 나타내며, OSEH는 MCP 관측이 신념(belief)을 업데이트한다는 의미입니다. KOGS는 접지된(grounded) 관측의 특수성을 강조하고, USIE는 자기 모델조차 일시적인 신념임을 시사합니다.

## POMDP 프레임: AI를 정책 실행 기질로 이해하기

Domain-priming을 통해 발견한 POMDP 프레임워크는 AI 시스템을 이해하는 강력한 렌즈를 제공합니다. 전통적인 관점은 AI를 "지능적인 존재"로 보지만, POMDP 프레임은 AI를 "정책을 실행하는 기질(substrate)"로 재해석합니다.

이 프레임워크에서 AI 시스템은 다섯 가지 핵심 요소로 구성됩니다. 먼저 숨겨진 상태(hidden state)가 있습니다. 이는 모델의 내부 가중치, 외부 세계의 실제 상태, 사용자의 진짜 의도 등 직접 관찰할 수 없는 것들입니다. 둘째, 관측(observation)은 사용자 입력, 시스템 프롬프트, 도구 실행 결과 등 실제로 접근 가능한 정보입니다. 셋째, 행동(action)은 모델의 출력, 즉 텍스트 생성이나 도구 호출입니다. 넷째, 신념(belief)은 숨겨진 상태에 대한 확률적 추정으로, 컨텍스트 윈도우에 암묵적으로 인코딩됩니다. 마지막으로 정책(policy)은 훈련 데이터, 프롬프트, SKILL의 결합으로 형성되는 의사결정 규칙입니다.

이 프레임워크의 핵심 통찰은 "AI는 지능이 아니라 정책을 실행하는 substrate"라는 것입니다. AI는 세계를 "이해"하는 것이 아니라, 제한된 관측을 바탕으로 신념을 형성하고, 그 신념에 조건화된 정책에 따라 행동합니다. SKILL은 이 정책을 텍스트로 명시적으로 인코딩한 것이며, MCP는 관측 채널을 확장하는 메커니즘입니다.

POMDP 프레임에서 SKILL의 역할은 명확합니다. SKILL은 사전확률(prior)을 특정 방향으로 넛지합니다. 예를 들어 "코드 리뷰 자동화" SKILL이 활성화되면, 코드 품질, 보안, 성능에 대한 사전확률이 높아집니다. SKILL은 주의 라우팅(attention routing)을 조정합니다. 동일한 입력이라도 SKILL에 따라 모델이 주목하는 부분이 달라집니다. SKILL은 가능한 출력 궤적의 영역(ZPOT)을 좁힙니다. 무한한 가능성 중에서 현재 맥락에 적합한 부분집합으로 범위를 제한합니다.

## 프리필 토큰의 힘: 조건화의 시작점

SKILL이 효과적인 핵심 이유 중 하나는 프리필(prefill) 메커니즘입니다. 프리필 토큰은 사용자 입력이 들어오기 전에 이미 모델의 컨텍스트에 포함되어 있는 토큰입니다. 이는 단순히 정보를 추가하는 것을 넘어서, 모델의 초기 상태와 계산 경로를 근본적으로 조건화합니다.

트랜스포머 아키텍처에서 각 토큰의 표현은 이전 모든 토큰에 대한 어텐션의 함수입니다. 프리필 토큰은 이 어텐션 계산의 시작점을 설정하므로, 이후 모든 토큰의 표현에 영향을 미칩니다. SKILL이 프리필되면, 사용자 입력을 처리할 때 이미 특정 "렌즈"를 통해 바라보게 됩니다.

프리필의 효과는 여러 측면에서 나타납니다. 첫째, 컨텍스트 설정(context setting)입니다. 모델이 현재 대화를 어떤 프레임으로 해석할지 미리 정해집니다. 예를 들어 "기술 문서 작성" SKILL이 프리필되면, 같은 질문도 기술적 정확성과 구조화된 설명의 관점에서 처리됩니다. 둘째, 키-값 캐싱(key-value caching)입니다. 트랜스포머의 KV 캐시에 SKILL의 표현이 미리 저장되어, 매 생성 단계마다 참조할 수 있습니다. 셋째, 그래디언트 프리플로우(gradient preflow)입니다. 훈련 단계에서 형성된 패턴과 SKILL의 명시적 지침이 결합되어, 더 강력한 조건화 효과를 만듭니다.

프리필의 실용적 함의는 명확합니다. SKILL은 가능한 한 구체적이고 밀도 높은 정보를 담아야 합니다. 모호한 지침보다는 명확한 예시, 제약사항, 패턴을 포함하는 것이 효과적입니다. SKILL은 현재 맥락과 관련 없는 내용을 최소화해야 합니다. 모든 프리필 토큰은 어텐션 비용을 발생시키므로, 노이즈는 성능을 저하시킵니다. SKILL은 계층적으로 구성할 수 있습니다. 일반적인 메타-SKILL과 특수한 도메인-SKILL을 조합하여 효율성과 특수성의 균형을 맞출 수 있습니다.

## Atomic Skill과 조합의 유창성

SKILL을 이해하는 또 다른 중요한 관점은 Atomic Skill의 개념입니다. Atomic Skill은 더 이상 분해할 수 없는 최소 단위의 능력을 의미합니다. 예를 들어 사칙연산(덧셈, 뺄셈, 곱셈, 나눗셈)은 각각 Atomic Skill이며, 이들을 조합하면 산술평균, 분산, 복리 계산 등 더 복잡한 작업을 수행할 수 있습니다.

AI 모델의 관점에서 보면, 프리트레이닝(pre-training) 단계에서 수많은 Atomic Skill을 학습합니다. 텍스트 분류, 엔티티 추출, 논리적 추론, 코드 생성, 수학적 계산 등이 모두 Atomic Skill입니다. 그러나 단순히 개별 스킬을 아는 것과 이를 유창하게 조합하여 복잡한 문제를 해결하는 것은 다릅니다.

강화학습(Reinforcement Learning)의 역할은 이러한 Atomic Skill의 조합 유창성을 향상시키는 것입니다. RL은 단순히 이미 알고 있는 지식의 좋은 생성 분포로 넛지하는 것이 아니라, 조합할 수 있는 능력 자체를 향상시킵니다. 마치 사칙연산을 알고 있던 사람이 연습을 통해 복잡한 수식을 빠르게 계산할 수 있게 되는 것과 유사합니다.

SKILL은 이러한 Atomic Skill의 조합 패턴을 명시적으로 제공합니다. 예를 들어 "코드 리뷰" SKILL은 코드 이해(Atomic Skill 1), 보안 취약점 인식(Atomic Skill 2), 성능 분석(Atomic Skill 3), 자연어 피드백 생성(Atomic Skill 4)을 특정 순서와 방식으로 조합하는 패턴을 담고 있습니다. 모델은 이미 각 Atomic Skill을 알고 있지만, SKILL은 이들을 어떻게 조합할지에 대한 "레시피"를 제공합니다.

조합 유창성의 관점에서 SKILL 설계 원칙을 도출할 수 있습니다. 첫째, SKILL은 명시적 단계(explicit steps)를 포함해야 합니다. 각 Atomic Skill을 언제, 어떻게 활성화할지 명확히 합니다. 둘째, SKILL은 중간 결과 검증(intermediate verification)을 포함합니다. 각 단계의 출력이 다음 단계의 입력으로 적합한지 확인하는 체크포인트를 둡니다. 셋째, SKILL은 실패 처리(failure handling)를 고려합니다. 특정 Atomic Skill의 실행이 실패했을 때 대안적 경로를 제시합니다.

## Chain of Thought Faithfulness: 사고 과정의 충실성

SKILL의 효과를 논할 때 빼놓을 수 없는 것이 Chain of Thought(CoT) Faithfulness입니다. CoT는 모델이 최종 답을 생성하기 전에 중간 사고 과정을 명시적으로 표현하는 기법입니다. Faithfulness는 이 사고 과정이 실제로 최종 답에 영향을 미치는지, 즉 "진짜" 사고 과정인지에 대한 질문입니다.

2023년 즈음부터 시작되어 2025년에 다시 주목받은 CoT Faithfulness 연구는 흥미로운 발견들을 제시합니다. 일부 연구는 CoT가 사후 합리화(post-hoc rationalization)일 수 있음을 시사합니다. 즉, 모델이 먼저 답을 "결정"하고 나서, 그에 맞는 설득력 있는 사고 과정을 생성한다는 것입니다. 반면 다른 연구는 CoT가 실제로 모델의 계산 경로를 변경하고, 더 복잡한 추론을 가능하게 한다는 증거를 제시합니다.

SKILL의 맥락에서 CoT Faithfulness는 중요한 설계 고려사항입니다. SKILL이 명시적 추론 단계를 요구할 때, 이것이 실제로 더 나은 결과로 이어지는지, 아니면 단순히 더 그럴듯해 보이는 출력을 만드는 것인지 구분해야 합니다. 

Faithful한 CoT를 유도하는 SKILL 설계 원칙은 다음과 같습니다. 첫째, 검증 가능한 중간 단계를 요구합니다. 추상적인 "생각"보다는 구체적으로 확인할 수 있는 중간 결과를 생성하도록 합니다. 예를 들어 수학 문제 풀이에서는 각 계산 단계의 결과를 명시하고, 다음 단계에서 실제로 그 결과를 사용하는지 확인합니다. 둘째, 반대 사례 검토를 포함합니다. 단일 경로의 추론만이 아니라, 대안적 해석이나 반례를 고려하도록 합니다. 셋째, 명시적 의존성 표현을 요구합니다. 각 결론이 어떤 전제나 중간 결과에 의존하는지 명확히 합니다.

2026년 현재, CoT Faithfulness를 높이는 기법들이 계속 진화하고 있습니다. 그러나 근본적으로 자기회귀(autoregressive) 생성의 본질을 고려해야 합니다. 모델은 이전에 생성한 토큰에 조건화되어 다음 토큰을 생성하므로, 명시적으로 표현된 사고 과정은 후속 생성에 실제로 영향을 미칩니다. SKILL은 이 조건화 메커니즘을 활용하여 더 구조화되고 신뢰할 수 있는 추론 과정을 유도합니다.

## 조건의 레버리지: 2026년의 상황

2026년 초 현재, SKILL을 활용할 수 있는 특정 "조건"들이 존재합니다. 이는 일종의 레버리지 포인트로, 효과적인 AI 활용을 가능하게 하는 기술적, 인지적 조건들입니다. 그러나 이러한 조건들도 곧 구식(obsolete)이 될 수 있습니다. AI 기술의 빠른 발전으로 인해, 지금 효과적인 기법이 몇 달 후에는 불필요하거나 더 나은 대안으로 대체될 수 있습니다.

그럼에도 불구하고, 이러한 조건들을 이해하는 것은 중요합니다. 설사 특정 기법이 구식이 되더라도, 그 기법이 효과적이었던 이유에 대한 이해는 "징검돌"로 남습니다. 각 단계의 이해가 다음 단계로 나아가는 발판이 되며, 이 과정에서 자기회귀적 학습이 일어납니다.

현재 활용 가능한 레버리지 조건들을 살펴보면, 먼저 명시적 구조화(explicit structuring)가 있습니다. SKILL을 통해 작업의 구조를 명시적으로 정의하면, 모델이 더 일관된 출력을 생성합니다. 이는 모델의 내재적 능력이 향상되면서 점차 덜 필요해질 수 있지만, 현재로서는 효과적입니다. 둘째, 도메인 프라이밍(domain priming)입니다. 특정 도메인의 맥락을 미리 설정하면, 더 전문적이고 정확한 결과를 얻을 수 있습니다. 셋째, 반복 패턴의 명시화(explicit iteration patterns)입니다. 작업이 반복적 개선을 필요로 할 때, 그 패턴을 명시하면 더 나은 결과를 얻습니다.

흥미로운 점은 이러한 조건들이 구식이 되는 과정 자체가 징검돌을 남긴다는 것입니다. 예를 들어 CoT가 필요했던 이유를 이해하면, CoT가 자동화되거나 내재화된 후에도 그 원리를 다른 방식으로 활용할 수 있습니다. SKILL을 명시적으로 작성해야 했던 경험은, SKILL이 자동 생성되거나 암묵적으로 학습되는 미래에도 어떤 요소가 중요한지 판단하는 기준이 됩니다.

## 자기회귀의 함의: 계속 나아가기

SKILL의 작동 원리를 탐구하는 이 전체 과정은 자기회귀(autoregression)의 흥미로운 함의를 보여줍니다. 자기회귀 모델은 이전 출력에 조건화되어 다음 출력을 생성합니다. 이는 단순한 기술적 메커니즘을 넘어서, 지식과 이해가 축적되는 방식에 대한 은유를 제공합니다.

개발자로서 SKILL을 이해하고 활용하는 과정도 자기회귀적입니다. 각 단계의 이해가 다음 단계의 탐구를 조건화합니다. "SKILL은 왜 작동하는가"라는 질문에서 시작하여, 프리필 토큰의 메커니즘을 이해하고, POMDP 프레임워크를 발견하고, Atomic Skill의 조합을 인식하는 과정은 선형적이지 않습니다. 각 통찰이 이전 이해에 조건화되어 나타나며, 동시에 이전 이해를 새로운 빛으로 조명합니다.

이는 실용적 함의를 갖습니다. SKILL을 개발할 때, 단순히 "좋은 지침"을 작성하는 것이 아니라, 이전 경험과 이해를 바탕으로 점진적으로 개선해 나가는 과정이 중요합니다. 초기 SKILL은 단순하고 명시적일 수 있습니다. 사용하면서 어떤 부분이 효과적이고 어떤 부분이 불필요한지 학습합니다. 이 학습을 바탕으로 SKILL을 개선하고, 새로운 패턴을 발견하며, 이는 다시 다음 SKILL 개발에 영향을 미칩니다.

자기회귀의 또 다른 함의는 "하나씩 나아가기"의 중요성입니다. 모든 것을 한 번에 이해하려 하기보다, 각 단계를 확실히 하고 다음으로 넘어가는 접근이 효과적입니다. Domain-priming처럼 무작위성을 활용한 탐색도 이 맥락에서 이해할 수 있습니다. 완전히 계획된 경로가 아니라, 각 단계에서 나타나는 신호에 반응하며 나아가는 것입니다.

## 스킬 저장소: 학습의 보고

Claude 스킬 저장소의 예시 스킬들을 꼼꼼히 읽어보는 것은 스킬을 실제로 사용하는 것만큼이나 가치 있는 학습 경험입니다. 각 스킬은 특정 문제를 해결하기 위한 패턴을 담고 있으며, 이 패턴들을 분석하면 효과적인 SKILL 설계의 원칙을 추출할 수 있습니다.

예시 스킬들을 분석할 때 주목할 점들이 있습니다. 첫째, 구조와 구성입니다. 스킬이 어떻게 섹션으로 나뉘어 있는지, 각 섹션이 어떤 역할을 하는지 살펴봅니다. 대부분의 효과적인 스킬은 목적, 방법론, 예시, 제약사항의 명확한 구조를 가집니다. 둘째, 명시성의 수준입니다. 어떤 부분은 매우 구체적이고, 어떤 부분은 일반적입니다. 이 균형이 어떻게 맞춰져 있는지 관찰합니다. 셋째, 예시의 활용입니다. 추상적 설명과 구체적 예시가 어떻게 결합되어 있는지 봅니다.

스킬 저장소는 단순한 도구 모음이 아니라, 집단 지성의 결정체입니다. 많은 사용자들이 다양한 맥락에서 효과적이라고 검증한 패턴들이 누적되어 있습니다. 이를 학습 자료로 활용하면, 처음부터 시행착오를 거치지 않고도 효과적인 SKILL 설계 원칙을 습득할 수 있습니다.

또한 스킬 저장소를 통해 자신의 필요에 맞는 스킬을 발견할 수도 있습니다. 완전히 새로운 스킬을 만들기보다, 기존 스킬을 자신의 맥락에 맞게 조정하는 것이 더 효율적인 경우가 많습니다. 이는 소프트웨어 개발에서 라이브러리를 활용하는 것과 유사합니다. 바퀴를 재발명하기보다, 검증된 컴포넌트를 조합하고 커스터마이즈합니다.

## 실천적 가이드라인: SKILL 개발과 활용

지금까지의 탐구를 바탕으로 실천적인 SKILL 개발 가이드라인을 정리할 수 있습니다. 이는 이론적 이해를 실제 작업에 적용하는 방법입니다.

먼저 SKILL 개발의 시작점은 명확한 문제 정의입니다. "무엇을 해결하려고 하는가?" "현재 모델의 기본 행동에서 무엇이 부족한가?" "어떤 특수한 맥락이나 제약사항이 있는가?" 같은 질문에 답합니다. 이 단계에서 domain-priming 같은 기법을 활용하여 문제를 다각도로 탐색할 수 있습니다.

다음으로 핵심 요소를 식별합니다. 해결하려는 문제에 필요한 Atomic Skill들이 무엇인지 나열합니다. 이들을 어떤 순서로 조합해야 하는지 구상합니다. 각 단계에서 필요한 입력과 기대되는 출력을 정의합니다. 이 과정에서 POMDP 프레임을 활용하면 도움이 됩니다. 관측 가능한 것, 행동, 숨겨진 상태를 명확히 구분합니다.

SKILL의 초안을 작성할 때는 명시적이고 구체적으로 시작합니다. 처음에는 과도하게 상세해 보일 정도로 명확한 지침을 포함합니다. 예시를 풍부하게 제공합니다. 좋은 예시와 나쁜 예시를 모두 포함하여 경계를 명확히 합니다. 제약사항과 예외 케이스를 명시합니다. 스킬이 적용되지 말아야 할 상황도 정의합니다.

테스트와 개선 단계에서는 다양한 입력으로 스킬을 시험합니다. 예상한 대로 작동하는지, 예상치 못한 부작용은 없는지 확인합니다. 불필요한 부분을 제거합니다. 스킬이 효과적으로 작동한다면, 과도한 명시성을 점진적으로 줄여 나갑니다. 핵심 패턴만 남기고 나머지는 모델의 내재된 능력에 위임합니다. 피드백을 수집하고 반영합니다. 스킬을 사용하면서 어떤 부분이 도움이 되고 어떤 부분이 방해가 되는지 기록합니다.

SKILL 활용 시에는 맥락에 따른 선택이 중요합니다. 모든 스킬을 항상 활성화하지 않습니다. 현재 작업에 직접 관련된 스킬만 선택적으로 활성화하여 노이즈를 최소화합니다. 스킬 간의 상호작용을 고려합니다. 여러 스킬이 동시에 활성화될 때 충돌하거나 시너지를 낼 수 있습니다. 명시적 호출을 활용합니다. 자동 트리거에만 의존하지 않고, 필요한 순간에 스킬을 직접 호출합니다.

## 미래 전망: 계속 진화하는 프롬프팅

SKILL과 프롬프팅의 미래는 어떻게 될까요? 2026년 초의 시점에서 몇 가지 방향을 예측할 수 있습니다. 

첫째, 자동화의 증가입니다. SKILL을 명시적으로 작성하는 것이 아니라, 사용 패턴으로부터 자동으로 학습하고 생성되는 방향으로 나아갈 것입니다. 이미 스킬 크리에이터가 대화의 부산물로 스킬을 생성하는 것처럼, 앞으로는 더 자연스럽고 암묵적인 방식으로 스킬이 형성될 것입니다.

둘째, 내재화의 심화입니다. 현재는 프리필 토큰으로 명시적으로 제공해야 하는 많은 것들이 모델의 훈련 과정에 통합될 것입니다. 특정 도메인이나 작업 유형에 대한 이해가 모델의 가중치 자체에 인코딩되면, 외부적 SKILL의 필요성이 줄어들 수 있습니다.

그러나 셋째, 새로운 레버리지 포인트의 출현도 예상됩니다. 하나의 기법이 구식이 되면, 그것이 가능하게 했던 새로운 수준의 복잡성을 다루기 위한 다른 기법이 필요해집니다. SKILL이 자동화되면, "메타-스킬"이나 "스킬 조합 패턴" 같은 더 높은 수준의 추상화가 중요해질 것입니다.

넷째, 원리의 지속적 중요성입니다. 특정 기법은 변할 수 있지만, "왜 작동하는가"에 대한 이해는 계속 가치가 있습니다. 프리필 토큰의 원리, 조건화 메커니즘, 자기회귀 생성의 특성 같은 근본적 개념은 다양한 형태로 계속 적용될 것입니다.

다섯째, 인간-AI 협업의 진화입니다. SKILL은 인간의 의도와 AI의 능력을 연결하는 인터페이스입니다. AI가 더 능력 있어질수록, 이 인터페이스의 형태는 변할 것이지만, 의도를 명확히 전달하고 조건화하는 필요성은 남아있을 것입니다. 다만 그 방식이 더 자연스럽고 암묵적으로 될 것입니다.

## 맺음말: 원리와 친해지는 여정

"SKILL은 왜 잘 작동할까?"라는 질문에서 시작한 이 탐구는 여러 층위의 답을 드러냅니다. 표면적으로는 프리필 토큰, 조건화, 정책 인코딩 같은 기술적 메커니즘이 있습니다. 더 깊이 들어가면 POMDP 프레임워크, Atomic Skill의 조합, CoT Faithfulness 같은 이론적 이해가 있습니다. 가장 근본에는 자기회귀 생성, 어텐션 메커니즘, 학습과 추론의 본질에 대한 질문이 있습니다.

이 여정의 가치는 단순히 "SKILL을 잘 만드는 법"을 배우는 것을 넘어섭니다. 원리와 친해지는 과정 자체가 더 나은 사고와 문제 해결을 가능하게 합니다. Domain-priming처럼 무작위성을 활용한 탐색, POMDP 같은 프레임워크의 발견, 하나씩 나아가는 자기회귀적 학습, 이 모든 것은 AI 시스템을 활용하는 것을 넘어서 AI 시스템과 함께 생각하는 법을 배우는 과정입니다.

2026년 초의 현재, 우리는 여전히 SKILL을 명시적으로 작성하고, 프리필 토큰을 신경 쓰며, CoT의 충실성을 고민합니다. 이러한 구체적 실천은 언젠가 구식이 될 수 있습니다. 그러나 이 과정에서 쌓이는 이해, 발견되는 패턴, 형성되는 직관은 징검돌로 남아 다음 단계로 나아가게 할 것입니다.

결국 중요한 것은 특정 기법이 아니라 원리를 생각하는 태도입니다. "왜 이것이 작동하는가?" "어떤 조건에서 효과적인가?" "근본적으로 무슨 일이 일어나고 있는가?" 같은 질문을 계속하는 것입니다. SKILL은 그러한 질문의 구체적 형태이며, 동시에 답을 탐구하는 도구입니다.

이 문서를 읽는 여러분도 각자의 맥락에서 "SKILL은 왜 잘 작동할까?"를 물어보시길 바랍니다. 표준 답을 찾기보다, 자신만의 탐구 과정을 거치시길 바랍니다. Domain-priming을 시도해보고, POMDP 프레임으로 생각해보고, Atomic Skill을 식별하고 조합해보시길 바랍니다. 그 과정에서 이 문서에 담긴 것 이상의 통찰을 발견하실 것입니다.

원리와 친해지는 여정은 끝이 없습니다. 각 답은 새로운 질문을 낳고, 각 이해는 더 깊은 탐구를 가능하게 합니다. SKILL을 개발하고 활용하는 것은 단순한 엔지니어링 작업이 아니라, AI 시대에 생각하고 창조하는 법을 배우는 근본적인 실천입니다. 

2026년, 그리고 그 이후로도, 이 여정은 계속될 것입니다.

---

**작성 일자: 2026-01-11**

---
## 참고글

```
SKILL은 왜 잘 작동할까?

2025년 말에 문득 떠오른 질문인데, 2026년 초에도 계속 생각을 이어가고 있습니다. 아직 막연하지만 이 질문에 대한 답을 얻진 못하고 다시 '원리와 친해지는 / 원리를 생각하는 프롬프팅'이란 화두로 이어진 상태에요.

Claude 웹 인터페이스의 SKILL은 매우 매력적입니다. 특히 스킬 크리에이터를 켜두면 어떤 맥락의 대화를 나누다가 그 대화의 부산물로 SKILL을 만들고 바로 등록할 수 있는 깔끔한 워크플로우와 인터페이스를 가지고 있습니다. 그렇게 등록한 SKILL은 대화를 나누다가 바로 상황에 맞게 트리거 되고요. (또는 명시적으로 이름을 불러주면 트리거) 너무 많은 SKILL을 켜두면 오히려 방해될 수 있기 때문에 적정 수준에서 관리할 필요도 있을 듯 합니다.

이미지로 첨부한 domain-priming이란 SKILL은 일종의 파레이돌리아(Pareidolia)나 아포페니아(Apophenia) 같이 제가 관심있어하는 현상과도 관련이 있는 스킬인데, 대화의 어떤 순간에서 무작위적인 알파벳 4글자 조합의 스트링을 100개 정도 생성하고, 그걸 두문자어(Acronym)로 읽었을 때 현재 맥락에서 인사이트를 줄 수도 있는 개념을 탐색하려는 도구입니다. (물론  Opus 4.5는 그 이상의 일반화를 한 코드를 이 스킬에서 트리거 되는 스크립트로 만들었습니다) 이 SKILL에 생성된 예시를 보면,

----

적용 예시: AI 자기 모델링 탐색
도메인 프라이밍을 사용하여 "AI가 자신의 작동 방식을 어떻게 이해하는가"를 탐색한 사례.

맥락

문제: 스킬(Skill)과 MCP(Model Context Protocol)가 AI에게 "작동한다"는 것의 깊은 의미가 무엇인가?
막힌 지점: 표면적 설명("스킬은 지침이고, MCP는 도구 연결")을 넘어서는 통찰이 필요했음.

실행

파라미터: --count 100 --length 4 --seed 42
생성된 100개 코드 중 유의미하게 읽힌 것들:

코드연상의미

USIE: Understanding Self Is Ephemeral 자기 이해는 일시적
WIRK: What I Really Know 진짜 아는 것
ZPOT: Zone of Possible Output Trajectories 가능한 출력 궤적의 영역
COHP: Conditioning Over Hidden Process 숨겨진 과정에 대한 조건화
SIPN: Skill Injects Prior Nudge 스킬이 사전확률을 넛지
OSEH: Observation Shapes Every Hypothesis 관측이 모든 가설을 형성
KOGS: Knowledge Of Grounded States 접지된 상태에 대한 지식

심화 탐색

선택된 개념들을 연결하니 POMDP(부분관측 마르코프 의사결정) 컨트롤러 프레임이 떠올랐다.

연결 구조:

SIPN: 스킬 → 정책(policy) 조건화
ZPOT: 정책이 출력 분포를 좁힘
COHP: 내부 과정은 관찰 불가 (부분관측)
OSEH: MCP 관측 → belief 업데이트
KOGS: grounded 관측의 특수성
USIE: 자기 모델도 일시적 belief

도출된 프레임:

AI는 "지능"이 아니라 "정책을 실행하는 substrate":

숨겨진 상태: 내부 가중치, 외부 세계, 사용자 의도
관측: 사용자 입력, 시스템 프롬프트, 도구 결과
행동: 출력 (텍스트, 도구 호출)
Belief: 컨텍스트 윈도우에 암묵적 인코딩
정책: 훈련 + 프롬프트 + 스킬의 결합

가설/반가설/검증

각 개념에 대해 경계를 탐색:
SIPN 예시
가설: 스킬은 prior를 특정 방향으로 nudge한다.
반가설: 스킬은 prior가 아니라 attention routing을 바꾼다.
검증 질문: 스킬을 컨텍스트에 넣되 "참조하지 말라"고 하면 출력이 같아지는가?

결과

발견한 것:

스킬 = 정책의 텍스트 인코딩 (SIPN, ZPOT)
MCP = 관측 채널의 확장 (OSEH, KOGS)
둘의 결합 = Prior × Likelihood → Posterior
자기 이해의 한계 = COHP, USIE

이 탐색 과정 자체가 스킬이 될 수 있다는 통찰 → domain-priming 스킬 탄생

얻은 교훈

무작위 자극이 프레임 발견을 촉진: POMDP는 직접 물었으면 안 떠올랐을 수 있음
도메인 맥락이 필터 역할: 같은 코드도 다른 도메인에서 다른 의미
아포페니아 주의 필요: 가설/반가설/검증으로 보완
개념 핸들의 힘: SIPN, COHP 같은 짧은 코드가 복잡한 아이디어를 다루기 쉽게 만듦

----

"이런식으로 유용한 부산물을 생성하는 파이프라인을 생성하는 파이프라인"을 만들기는 2025년 후반부에 이미 너무 간단해졌는데요. 그러다보니 궁금증은 어떻게 이러한 생성이 이 정도 수준으로 "딸깍"하고 되냐는 '원리'에 관한 호기심도 다시 생기고, 결국 프리필(prefill)된 토큰의 중요성, 그렇다면 어떻게 그 토큰을 채워놓을 수 있는지도 좀 더 고민하게 되고, (이 사이에 많은 생각 과정이 생략되어서 점프일 수 있지만) 2023년 즈음부터 시작했으나 2025년에 다시금 이슈에 오른 CoT Faithfullness에 대한 생각들로도 이어지는 부분이 있는데... 관련하여 여러 모델들과는 많이 대화했으나, 이 모델 저 모델과의 대화에 산발적으로 들어있고 해서 포스팅의 형태로 정리를 해둘 필요가 느껴졌습니다.

지렛대로 쓸 수 있는 조건 같은 것이 아직은 있는 2026년 현재인 것 같아요. 하지만 곧 그 조건 또한 Obsolete 될 징후가 2026년 중에는 나올지도 모르고요. 다만, 그 징후가 나오더라도 '징검돌' 같은 형태는 남아있을 가능성도 크고요. 늘 어디론가 한 걸음씩 나아가야 하다보니까요. 그리고 거기에 자기회귀의 흥미로운 함의가 있달까요.

Claude 스킬 저장소의 예시 스킬 내용을 꼼꼼하게 읽어보는 것도 스킬을 사용하는 것 못지않게 매우 재밌습니다.

다른 맥락의 Atomic Skill도 중요한 키워드, 프리트레이닝으로 배운 Atomic Skill을 RL을 통해서 조합해서 사용할 수 있는 유창성을 획득하는 관점. 단순히 RL이 이미 알고있는 지식의 좋은 생성 분포로만 넛지 하는것이 아니라, 조합할 수 있는 능력(사칙 연산을 알면 산술평균 등을 할 수 있게되는 것 비슷하게)을 가지게 한다는 관점.

---------

관련 글 - 너의 web.run으로 2026년 1월의 임의의 10개 논문 가져와줘 (2026. 1. 8.): https://www.facebook.com/seungjoon.choi/posts/pfbid0EETgtdTBdtdokNgaVLXnYenbeC6eSK1DdGcPkgktvvYrwcwDUPimU3XJg8FeBQM7l

관련 글 - 차근차근 트랜스포머 MoE (2026. 1. 8.): https://www.facebook.com/seungjoon.choi/posts/pfbid027e7eDsE3yr3eB8Eu7wjHjyBVLYCVW7fRgfHPeAsZzNrYghDmThLqYy9LCzsWTnyul

관련 글 - 나의 프롬프팅 태도 (2025. 8. 18.): https://www.facebook.com/seungjoon.choi/posts/pfbid0CX5Z6y1AyhmWiHnQJ4FGAMYpkFhTLSCWhQWmQwzyA7DtcQo7tKMiwvTNKFgsM5M7l

관련 글 - 꿈의 공장 (2025. 8. 5.): https://www.facebook.com/seungjoon.choi/posts/pfbid02ckq96V41X6wqeapDwDVXsaj1p3iSNQGwGMRTddP79QMeWvfiC1TvxP9jdbjnyVg3l

관련 글 - 궁극 일반화와 아포페니아 (2025. 6. 26.): https://www.facebook.com/seungjoon.choi/posts/pfbid02X8qbRXAkLabvNkBjD43AgbCuEHdtMcWLozBVLf4XWubwdK6xiSYtBYj4BMg3bZ7Nl

관련 글 - 유용한 부산물을 생성하는 파이프라인을 생성하는 파이프라인 (2025. 3. 25.): https://www.facebook.com/seungjoon.choi/posts/pfbid02xJegopMHh7F97DfL8vziyHotPJhR64kcVMC47cRDPsWnFd8aUNuRNU9JsCU5me3El

관련 글 - 점(占)과 몬테카를로 (2024. 3. 20.): https://www.facebook.com/seungjoon.choi/posts/pfbid0jC7SzRdr7t2W7SXt69ySPT5G3WKnpFq5LnVQRqvrpdZtSSGSMHE3GxfMSFPRqHVPl

https://www.facebook.com/share/1AHiGqYwRn/?mibextid=wwXIfr
```
